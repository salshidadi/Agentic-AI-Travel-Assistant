{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 4: A/B Testing & Model Improvement\n",
    "\n",
    "In this phase, we conduct an A/B test to compare our best Phase 2 model (Control) against a proposed improved version (Treatment). We define specific discrete and continuous metrics to evaluate performance comprehensively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Metrics Definition\n",
    "\n",
    "We selected the following metrics to evaluate the models:\n",
    "\n",
    "### Discrete Metrics (Classification Quality)\n",
    "1. **Accuracy**: The ratio of correctly predicted observations to total observations.\n",
    "2. **Macro F1-Score**: The harmonic mean of precision and recall, averaged across classes (crucial for our imbalanced data).\n",
    "3. **Macro Precision**: Measures how many selected items are relevant, averaged across classes.\n",
    "\n",
    "### Continuous Metrics (Probabilistic & Operational)\n",
    "1. **Log Loss (Cross-Entropy)**: Measures the performance of a classification model where the prediction input is a probability value between 0 and 1. Lower is better.\n",
    "2. **ROC-AUC Score**: Area Under the Receiver Operating Characteristic Curve. Measures the ability of the classifier to distinguish between classes. Higher is better.\n",
    "3. **Inference Latency (ms)**: The average time taken to predict a single sample. Lower is better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    f1_score, \n",
    "    precision_score, \n",
    "    log_loss, \n",
    "    roc_auc_score\n",
    ")\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Samples: 959\n",
      "Test Samples: 240\n"
     ]
    }
   ],
   "source": [
    "train_path = \"Dataset/phase2_outputs/conversation2_train.csv\"\n",
    "test_path = \"Dataset/phase2_outputs/conversation2_test.csv\"\n",
    "\n",
    "try:\n",
    "    train_df = pd.read_csv(train_path)\n",
    "    test_df = pd.read_csv(test_path)\n",
    "except FileNotFoundError:\n",
    "    raise FileNotFoundError(\"Phase 2 outputs not found. Please run Phase 2 notebook first.\")\n",
    "\n",
    "# Ensure string types\n",
    "X_train = train_df['utterance'].astype(str)\n",
    "y_train = train_df['intent']\n",
    "X_test = test_df['utterance'].astype(str)\n",
    "y_test = test_df['intent']\n",
    "\n",
    "# Label Encoding for Log Loss / AUC calculation\n",
    "le = LabelEncoder()\n",
    "y_train_enc = le.fit_transform(y_train)\n",
    "y_test_enc = le.transform(y_test)\n",
    "labels = le.classes_\n",
    "\n",
    "print(f\"Training Samples: {len(X_train)}\")\n",
    "print(f\"Test Samples: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model A: Control (Previous Best)\n",
    "\n",
    "Our previous best model was the **Linear SVM**. However, standard SVMs do not output probabilities required for Log Loss. To enable fair A/B testing on continuous metrics, we wrap the Linear SVM in `CalibratedClassifierCV` (Platt Scaling)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:811: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro F1</th>\n",
       "      <th>Macro Precision</th>\n",
       "      <th>Log Loss</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>Latency (ms)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Model A (Control)</th>\n",
       "      <td>0.9625</td>\n",
       "      <td>0.968881</td>\n",
       "      <td>0.971984</td>\n",
       "      <td>0.151515</td>\n",
       "      <td>0.996458</td>\n",
       "      <td>0.031528</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Accuracy  Macro F1  Macro Precision  Log Loss   ROC AUC  \\\n",
       "Model A (Control)    0.9625  0.968881         0.971984  0.151515  0.996458   \n",
       "\n",
       "                   Latency (ms)  \n",
       "Model A (Control)      0.031528  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define Model A Pipeline\n",
    "model_a = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words='english', ngram_range=(1, 2))),\n",
    "    ('clf', CalibratedClassifierCV(LinearSVC(class_weight='balanced', random_state=42)))\n",
    "])\n",
    "\n",
    "# Train\n",
    "start_train_a = time.time()\n",
    "model_a.fit(X_train, y_train_enc)\n",
    "train_time_a = time.time() - start_train_a\n",
    "\n",
    "# Predict & Measure Latency\n",
    "start_inf_a = time.time()\n",
    "preds_a = model_a.predict(X_test)\n",
    "probs_a = model_a.predict_proba(X_test)\n",
    "inf_time_a = (time.time() - start_inf_a) / len(X_test) * 1000 # ms per sample\n",
    "\n",
    "# Calculate Metrics\n",
    "metrics_a = {\n",
    "    \"Accuracy\": accuracy_score(y_test_enc, preds_a),\n",
    "    \"Macro F1\": f1_score(y_test_enc, preds_a, average='macro'),\n",
    "    \"Macro Precision\": precision_score(y_test_enc, preds_a, average='macro'),\n",
    "    \"Log Loss\": log_loss(y_test_enc, probs_a),\n",
    "    \"ROC AUC\": roc_auc_score(y_test_enc, probs_a, multi_class='ovr', average='macro'),\n",
    "    \"Latency (ms)\": inf_time_a\n",
    "}\n",
    "\n",
    "display(pd.DataFrame([metrics_a], index=[\"Model A (Control)\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model B: Treatment (Improved Strategy)\n",
    "\n",
    "### Improvement Hypothesis\n",
    "1. **Data Augmentation**: The `book_hotel` intent is severely underrepresented (2 samples). We hypothesize that adding synthetic examples will improve the model's ability to recognize this intent.\n",
    "2. **Algorithm Enhancement (Ensemble)**: We replace the single SVM with a **VotingClassifier** (SVM + Logistic Regression). Logistic Regression provides naturally better-calibrated probabilities, potentially improving Log Loss and AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 10 samples. New training size: 969\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro F1</th>\n",
       "      <th>Macro Precision</th>\n",
       "      <th>Log Loss</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>Latency (ms)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Model B (Treatment)</th>\n",
       "      <td>0.941667</td>\n",
       "      <td>0.822735</td>\n",
       "      <td>0.809911</td>\n",
       "      <td>0.209622</td>\n",
       "      <td>0.99666</td>\n",
       "      <td>0.035373</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Accuracy  Macro F1  Macro Precision  Log Loss  ROC AUC  \\\n",
       "Model B (Treatment)  0.941667  0.822735         0.809911  0.209622  0.99666   \n",
       "\n",
       "                     Latency (ms)  \n",
       "Model B (Treatment)      0.035373  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. Data Augmentation\n",
    "new_samples = [\n",
    "    (\"I want to book a hotel room\", \"book_hotel\"),\n",
    "    (\"Reserve a suite for me\", \"book_hotel\"),\n",
    "    (\"I need a reservation at the Hilton\", \"book_hotel\"),\n",
    "    (\"Can you find me a place to stay?\", \"book_hotel\"),\n",
    "    (\"I'm looking for accommodation\", \"book_hotel\"),\n",
    "    (\"Book a double room for 2 nights\", \"book_hotel\"),\n",
    "    (\"I'd like to make a hotel reservation\", \"book_hotel\"),\n",
    "    (\"Find me a hotel in Paris\", \"book_hotel\"),\n",
    "    (\"Reserve a room\", \"book_hotel\"),\n",
    "    (\"I need to book a place\", \"book_hotel\")\n",
    "]\n",
    "new_df = pd.DataFrame(new_samples, columns=['utterance', 'intent'])\n",
    "train_df_aug = pd.concat([train_df, new_df], ignore_index=True)\n",
    "\n",
    "# Re-encode labels with augmented data (though classes are same)\n",
    "X_train_aug = train_df_aug['utterance'].astype(str)\n",
    "y_train_aug = train_df_aug['intent']\n",
    "y_train_aug_enc = le.transform(y_train_aug)\n",
    "\n",
    "print(f\"Added {len(new_df)} samples. New training size: {len(X_train_aug)}\")\n",
    "\n",
    "# 2. Algorithm: Voting Classifier (SVM + LR)\n",
    "clf1 = CalibratedClassifierCV(LinearSVC(class_weight='balanced', random_state=42))\n",
    "clf2 = LogisticRegression(class_weight='balanced', random_state=42, max_iter=1000)\n",
    "voting_clf = VotingClassifier(estimators=[('svm', clf1), ('lr', clf2)], voting='soft')\n",
    "\n",
    "model_b = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words='english', ngram_range=(1, 2), min_df=1)),\n",
    "    ('clf', voting_clf)\n",
    "])\n",
    "\n",
    "# Train\n",
    "start_train_b = time.time()\n",
    "model_b.fit(X_train_aug, y_train_aug_enc)\n",
    "train_time_b = time.time() - start_train_b\n",
    "\n",
    "# Predict\n",
    "start_inf_b = time.time()\n",
    "preds_b = model_b.predict(X_test)\n",
    "probs_b = model_b.predict_proba(X_test)\n",
    "inf_time_b = (time.time() - start_inf_b) / len(X_test) * 1000\n",
    "\n",
    "# Calculate Metrics\n",
    "metrics_b = {\n",
    "    \"Accuracy\": accuracy_score(y_test_enc, preds_b),\n",
    "    \"Macro F1\": f1_score(y_test_enc, preds_b, average='macro'),\n",
    "    \"Macro Precision\": precision_score(y_test_enc, preds_b, average='macro'),\n",
    "    \"Log Loss\": log_loss(y_test_enc, probs_b),\n",
    "    \"ROC AUC\": roc_auc_score(y_test_enc, probs_b, multi_class='ovr', average='macro'),\n",
    "    \"Latency (ms)\": inf_time_b\n",
    "}\n",
    "\n",
    "display(pd.DataFrame([metrics_b], index=[\"Model B (Treatment)\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Comparison & Findings\n",
    "\n",
    "We compare the Control (A) and Treatment (B) across all metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_573b7_row0_col1, #T_573b7_row1_col4 {\n",
       "  background-color: #006837;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_573b7_row0_col4, #T_573b7_row1_col1 {\n",
       "  background-color: #a50026;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_573b7\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_573b7_level0_col0\" class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th id=\"T_573b7_level0_col1\" class=\"col_heading level0 col1\" >Macro F1</th>\n",
       "      <th id=\"T_573b7_level0_col2\" class=\"col_heading level0 col2\" >Macro Precision</th>\n",
       "      <th id=\"T_573b7_level0_col3\" class=\"col_heading level0 col3\" >Log Loss</th>\n",
       "      <th id=\"T_573b7_level0_col4\" class=\"col_heading level0 col4\" >ROC AUC</th>\n",
       "      <th id=\"T_573b7_level0_col5\" class=\"col_heading level0 col5\" >Latency (ms)</th>\n",
       "      <th id=\"T_573b7_level0_col6\" class=\"col_heading level0 col6\" >F1 Diff</th>\n",
       "      <th id=\"T_573b7_level0_col7\" class=\"col_heading level0 col7\" >LogLoss Diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_573b7_level0_row0\" class=\"row_heading level0 row0\" >Model A (Control)</th>\n",
       "      <td id=\"T_573b7_row0_col0\" class=\"data row0 col0\" >0.9625</td>\n",
       "      <td id=\"T_573b7_row0_col1\" class=\"data row0 col1\" >0.9689</td>\n",
       "      <td id=\"T_573b7_row0_col2\" class=\"data row0 col2\" >0.9720</td>\n",
       "      <td id=\"T_573b7_row0_col3\" class=\"data row0 col3\" >0.1515</td>\n",
       "      <td id=\"T_573b7_row0_col4\" class=\"data row0 col4\" >0.9965</td>\n",
       "      <td id=\"T_573b7_row0_col5\" class=\"data row0 col5\" >0.0315</td>\n",
       "      <td id=\"T_573b7_row0_col6\" class=\"data row0 col6\" >0.0000</td>\n",
       "      <td id=\"T_573b7_row0_col7\" class=\"data row0 col7\" >0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_573b7_level0_row1\" class=\"row_heading level0 row1\" >Model B (Treatment)</th>\n",
       "      <td id=\"T_573b7_row1_col0\" class=\"data row1 col0\" >0.9417</td>\n",
       "      <td id=\"T_573b7_row1_col1\" class=\"data row1 col1\" >0.8227</td>\n",
       "      <td id=\"T_573b7_row1_col2\" class=\"data row1 col2\" >0.8099</td>\n",
       "      <td id=\"T_573b7_row1_col3\" class=\"data row1 col3\" >0.2096</td>\n",
       "      <td id=\"T_573b7_row1_col4\" class=\"data row1 col4\" >0.9967</td>\n",
       "      <td id=\"T_573b7_row1_col5\" class=\"data row1 col5\" >0.0354</td>\n",
       "      <td id=\"T_573b7_row1_col6\" class=\"data row1 col6\" >-0.1461</td>\n",
       "      <td id=\"T_573b7_row1_col7\" class=\"data row1 col7\" >0.0581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1117fba4cd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_ad699_row0_col3, #T_ad699_row0_col5 {\n",
       "  background-color: #006837;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ad699_row1_col3, #T_ad699_row1_col5 {\n",
       "  background-color: #a50026;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_ad699\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_ad699_level0_col0\" class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th id=\"T_ad699_level0_col1\" class=\"col_heading level0 col1\" >Macro F1</th>\n",
       "      <th id=\"T_ad699_level0_col2\" class=\"col_heading level0 col2\" >Macro Precision</th>\n",
       "      <th id=\"T_ad699_level0_col3\" class=\"col_heading level0 col3\" >Log Loss</th>\n",
       "      <th id=\"T_ad699_level0_col4\" class=\"col_heading level0 col4\" >ROC AUC</th>\n",
       "      <th id=\"T_ad699_level0_col5\" class=\"col_heading level0 col5\" >Latency (ms)</th>\n",
       "      <th id=\"T_ad699_level0_col6\" class=\"col_heading level0 col6\" >F1 Diff</th>\n",
       "      <th id=\"T_ad699_level0_col7\" class=\"col_heading level0 col7\" >LogLoss Diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_ad699_level0_row0\" class=\"row_heading level0 row0\" >Model A (Control)</th>\n",
       "      <td id=\"T_ad699_row0_col0\" class=\"data row0 col0\" >0.9625</td>\n",
       "      <td id=\"T_ad699_row0_col1\" class=\"data row0 col1\" >0.9689</td>\n",
       "      <td id=\"T_ad699_row0_col2\" class=\"data row0 col2\" >0.9720</td>\n",
       "      <td id=\"T_ad699_row0_col3\" class=\"data row0 col3\" >0.1515</td>\n",
       "      <td id=\"T_ad699_row0_col4\" class=\"data row0 col4\" >0.9965</td>\n",
       "      <td id=\"T_ad699_row0_col5\" class=\"data row0 col5\" >0.0315</td>\n",
       "      <td id=\"T_ad699_row0_col6\" class=\"data row0 col6\" >0.0000</td>\n",
       "      <td id=\"T_ad699_row0_col7\" class=\"data row0 col7\" >0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ad699_level0_row1\" class=\"row_heading level0 row1\" >Model B (Treatment)</th>\n",
       "      <td id=\"T_ad699_row1_col0\" class=\"data row1 col0\" >0.9417</td>\n",
       "      <td id=\"T_ad699_row1_col1\" class=\"data row1 col1\" >0.8227</td>\n",
       "      <td id=\"T_ad699_row1_col2\" class=\"data row1 col2\" >0.8099</td>\n",
       "      <td id=\"T_ad699_row1_col3\" class=\"data row1 col3\" >0.2096</td>\n",
       "      <td id=\"T_ad699_row1_col4\" class=\"data row1 col4\" >0.9967</td>\n",
       "      <td id=\"T_ad699_row1_col5\" class=\"data row1 col5\" >0.0354</td>\n",
       "      <td id=\"T_ad699_row1_col6\" class=\"data row1 col6\" >-0.1461</td>\n",
       "      <td id=\"T_ad699_row1_col7\" class=\"data row1 col7\" >0.0581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1117fba4cd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "comparison = pd.DataFrame([metrics_a, metrics_b], index=[\"Model A (Control)\", \"Model B (Treatment)\"])\n",
    "comparison[\"F1 Diff\"] = comparison[\"Macro F1\"] - comparison[\"Macro F1\"].iloc[0]\n",
    "comparison[\"LogLoss Diff\"] = comparison[\"Log Loss\"] - comparison[\"Log Loss\"].iloc[0]\n",
    "\n",
    "display(comparison.style.format(\"{:.4f}\").background_gradient(cmap=\"RdYlGn\", subset=[\"Macro F1\", \"ROC AUC\"]))\n",
    "display(comparison.style.format(\"{:.4f}\").background_gradient(cmap=\"RdYlGn_r\", subset=[\"Log Loss\", \"Latency (ms)\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Findings\n",
    "\n",
    "1. **Discrete Metrics Decline**: The **Macro F1 score dropped** in Model B. This suggests that while we added data for `book_hotel`, the **Voting Classifier** (specifically the Logistic Regression component) or the synthetic data itself introduced confusion with other classes (e.g., `greeting` vs. `book_hotel`). The original SVM (Model A) was more robust to the specific noise in the zero-shot-labeled test set.\n",
    "2. **Log Loss Degradation**: Model B showed higher (worse) Log Loss. This indicates that the ensemble was *less confident* in its correct predictions or *more confident* in its wrong ones compared to the calibrated SVM alone.\n",
    "3. **AUC Stability**: The ROC-AUC remained very high (~0.99) for both, indicating that both models are excellent at ranking intents, even if the specific decision threshold (affecting F1) was suboptimal in Model B.\n",
    "4. **Latency**: Model B is slightly slower due to the overhead of running two classifiers (SVM + LR) and the voting mechanism.\n",
    "\n",
    "**Conclusion**: For this specific dataset, the **Control Model (Calibrated Linear SVM)** is superior. The attempt to improve via simple augmentation and ensembling failed to outperform the baseline, likely due to the small dataset size and the potential quality mismatch between synthetic data and the zero-shot labels in the test set."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
