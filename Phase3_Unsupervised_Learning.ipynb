# -------------------------------------------------------------------
# --- SWE485 - Phase 3: Unsupervised Learning (Complete Code) ---
# -------------------------------------------------------------------

# --- Step 1: Import Libraries ---
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
from sklearn.decomposition import PCA
import warnings

# Suppress warnings for a cleaner output
warnings.filterwarnings('ignore')

print("--- Step 1: Libraries imported successfully. ---")


# --- Step 2: Load and Prepare Data ---

# Adjust this path if your file is in a different location
file_path = './Dataset/customer_booking.csv' 

try:
    df = pd.read_csv(file_path)
except FileNotFoundError:
    print("Warning: '../Dataset/customer_booking.csv' not found. Trying 'customer_booking.csv' in the current directory.")
    try:
        df = pd.read_csv('customer_booking.csv')
    except FileNotFoundError:
        print("ERROR: Could not find 'customer_booking.csv'. Please check the file path.")
        # Exit or raise error if file is critical
        # For this script, we'll let it error out on the next step.

# IMPORTANT: Remove the class label per project instructions
if 'booking_complete' in df.columns:
    df_unsupervised = df.drop('booking_complete', axis=1)
    print("Removed 'booking_complete' label for clustering.")
else:
    df_unsupervised = df.copy()

# Define features for clustering
numeric_features = [
    'num_passengers', 
    'purchase_lead', 
    'length_of_stay', 
    'flight_hour',
    'flight_duration'
]

categorical_features = [
    'sales_channel', 
    'trip_type',
    'flight_day'
]

binary_features = [
    'wants_extra_baggage', 
    'wants_preferred_seat', 
    'wants_in_flight_meals'
]

# Combine all features we will use
features_to_use = numeric_features + categorical_features + binary_features
df_features = df_unsupervised[features_to_use].copy()

# Simple imputation: fill missing numeric values with the mean
for col in numeric_features:
    if df_features[col].isnull().any():
        df_features[col] = df_features[col].fillna(df_features[col].mean())

# Simple imputation: fill missing categorical values with the mode
for col in categorical_features:
    if df_features[col].isnull().any():
        df_features[col] = df_features[col].fillna(df_features[col].mode()[0])

print("--- Step 2: Data loaded and prepared. ---")


# --- Step 3: Preprocessing Pipeline ---
preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), numeric_features),
        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features),
        ('bin', 'passthrough', binary_features)
    ],
    remainder='drop'
)

print("Applying preprocessing pipeline...")
X_prepared = preprocessor.fit_transform(df_features)

print("--- Step 3: Preprocessing complete. ---")
print(f"Shape of prepared data: {X_prepared.shape}")


# --- Step 4: Algorithm Justification (Written part) ---
print("\n--- Step 4: Algorithm Justification (for your report) ---")
print("Algorithm: K-Means Clustering")
print("Justification: K-Means is efficient, scalable, and its centroids are highly interpretable,")
print("allowing us to build clear customer 'profiles'. Its 'Inertia' metric directly fulfills")
print("the 'Within-Cluster Sum of Squares' requirement.")


# --- Step 5: Find Optimal K (Elbow Method) ---
print("\n--- Step 5: Running Elbow Method (WCSS)... ---")
inertia_values = []
k_range = range(1, 11) # Test K from 1 to 10

for k in k_range:
    kmeans = KMeans(n_clusters=k, init='k-means++', n_init=10, random_state=42)
    kmeans.fit(X_prepared)
    inertia_values.append(kmeans.inertia_)

# Plot the Elbow Method
plt.figure(figsize=(10, 6))
plt.plot(k_range, inertia_values, marker='o', linestyle='--')
plt.title('Elbow Method for Optimal K (WCSS)')
plt.xlabel('Number of Clusters (K)')
plt.ylabel('Within-Cluster Sum of Squares (Inertia)')
plt.xticks(k_range)
plt.grid(True)
plt.show()

print("--> ANALYSIS REQUIRED: Look at the plot above. Find the 'elbow' point where the line")
print("    starts to flatten. This is your 'OPTIMAL_K'. We will use K=4 as an example.")


# --- Step 6: Train Final Model & Evaluate (Silhouette Score) ---
# !!! CHANGE THIS VALUE based on your elbow plot !!!
OPTIMAL_K = 4 

print(f"\n--- Step 6: Training final K-Means model with K={OPTIMAL_K}... ---")
kmeans_final = KMeans(n_clusters=OPTIMAL_K, init='k-means++', n_init=10, random_state=42)
kmeans_final.fit(X_prepared)

# Get the cluster assignments
cluster_labels = kmeans_final.labels_

print("Calculating Silhouette Score...")
# Note: Silhouette score can be slow on large datasets. We'll sample if > 10k rows
if X_prepared.shape[0] > 10000:
    print("Dataset is large, calculating silhouette score on a 10k sample...")
    from sklearn.utils import resample
    X_sample, labels_sample = resample(X_prepared, cluster_labels, n_samples=10000, random_state=42, stratify=cluster_labels)
    score = silhouette_score(X_sample, labels_sample)
else:
    score = silhouette_score(X_prepared, cluster_labels)

print(f"--> Silhouette Score for K={OPTIMAL_K}: {score:.3f}")
print("    (Score ranges from -1 to 1. A positive score is good.)")

# Add the cluster labels back to our *original* dataframe for analysis
df['cluster'] = cluster_labels


# --- Step 7: Visualize Clusters (PCA) ---
print("\n--- Step 7: Running PCA for 2D visualization... ---")
pca = PCA(n_components=2, random_state=42)
X_pca = pca.fit_transform(X_prepared)

# Create a new DataFrame for plotting
df_pca = pd.DataFrame(data=X_pca, columns=['PC1', 'PC2'])
df_pca['cluster'] = cluster_labels

# Plot the clusters
plt.figure(figsize=(12, 8))
sns.scatterplot(
    x='PC1', 
    y='PC2', 
    hue='cluster', 
    data=df_pca, 
    palette='viridis', 
    s=50, 
    alpha=0.7
)
plt.title('Customer Segments (Visualized with PCA)')
plt.xlabel('Principal Component 1')
plt.ylabel('Principal Component 2')
plt.legend(title='Cluster')
plt.grid(True)
plt.show()

print("--> ANALYSIS REQUIRED: The plot above shows your clusters.")
print("    Are they well-separated or do they overlap?")


# --- Step 8: Analyze Cluster Profiles ---
print("\n--- Step 8: Analyzing Cluster Profiles (The 'Insight') ---")

# Analyze numeric and binary features by cluster
print("\n--- Average values for Numeric/Binary features in each cluster ---")
cluster_analysis_mean = df.groupby('cluster')[numeric_features + binary_features].mean()
print(cluster_analysis_mean)

# Analyze categorical features by cluster
for col in categorical_features:
    print(f"\n--- Distribution of '{col}' in each cluster ---")
    # Using describe() to get top value and frequency
    print(df.groupby('cluster')[col].describe())

print("\n\n" + "="*70)
print("--- FINAL ANALYSIS (WRITE THIS IN YOUR REPORT) ---")
print("="*70)
print("\n### 3.1. Cluster Personas (Example Analysis)")
print("--> INSTRUCTIONS: Look at the tables above to write your analysis.")
print("    For example:\n")
print(
    "* **Cluster 0: 'The Planners'**\n"
    "    * **Analysis:** This group has the highest average `purchase_lead` (e.g., 150 days) and...\n"
    "    * **Insight:** These customers book far in advance.\n"
)
print(
    "* **Cluster 1: 'The Families'**\n"
    "    * **Analysis:** This group has the highest average `num_passengers` (e.g., 3.5) and `wants_extra_baggage`...\n"
    "    * **Insight:** These are families or groups who buy extras.\n"
)
print("    (Create a persona for each of your clusters...)\n")

print("\n### 3.2. Integration with Supervised Model (Phase 2)")
print("--> INSTRUCTIONS: Explain how this helps your Phase 2 model.\n")
print(
    "1.  **Feature Engineering:** The cluster label (e.g., 'Cluster 0', 'Cluster 1') can be added as a\n"
    "    new feature to our dataset for the supervised model.\n"
)
print(
    "2.  **Hypothesis:** The supervised model (SVM, Neural Net) will now learn that different 'customer types'\n"
    "    (our clusters) have different probabilities of completing a booking. For example, 'Last-Minute Travelers'\n"
    "    (Cluster 2) might be more likely to book than 'Planners' (Cluster 0).\n"
)
print(
    "3.  **Actionable Advice:** This allows our system to give smarter, personalized advice.\n"
    "    * If a user matches **'The Families' cluster**, the system can proactively suggest 'Add family meal plan?'.\n"
    "    * If a user matches **'The Planners' cluster**, the system can suggest 'Add travel insurance for your trip?'.\n"
)
print("\n--- End of Phase 3 ---")
