# -------------------------------------------------------------------
# --- SWE485 - Phase 3: Unsupervised Learning (Complete Code) ---
# -------------------------------------------------------------------

# --- Step 1: Import Libraries ---
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
from sklearn.decomposition import PCA
from sklearn.impute import SimpleImputer
from sklearn.pipeline import Pipeline
import warnings

# Suppress warnings for a cleaner output
warnings.filterwarnings('ignore')

print("--- Step 1: Libraries imported successfully. ---")


# --- Step 2: Load and Prepare Data ---

# Path relative to the /Unsupervised_Learning folder
file_path = '../Dataset/customer_booking.csv' 

try:
    df = pd.read_csv(file_path, encoding='latin1')
except FileNotFoundError:
    print(f"ERROR: File not found at {file_path}")
    print("Please ensure 'customer_booking.csv' is in a folder named 'Dataset' one level above this notebook.")
    # As a fallback, try reading from the current directory
    df = pd.read_csv('customer_booking.csv', encoding='latin1')


# --- IMPORTANT: Remove the class label (per Phase 3 instructions) ---
if 'booking_complete' in df.columns:
    df_cluster = df.drop('booking_complete', axis=1)
    print("Removed 'booking_complete' label for clustering.")
else:
    df_cluster = df.copy()

# --- Define Feature Types (based on your Phase 1 analysis) ---
# We'll drop high-cardinality text features like 'route' and 'booking_origin'
# as they are not suitable for K-Means without complex embedding.

numeric_features = [
    'num_passengers', 
    'purchase_lead', 
    'length_of_stay', 
    'flight_hour',
    'flight_duration'
]

categorical_features = [
    'sales_channel', 
    'trip_type',
    'flight_day'
]

# Binary features are already numeric (0/1), so we'll treat them as numeric
binary_features = [
    'wants_extra_baggage', 
    'wants_preferred_seat', 
    'wants_in_flight_meals'
]

# Combine all features we will use
features_to_use = numeric_features + categorical_features + binary_features
df_features = df_cluster[features_to_use].copy()

print(f"--- Step 2: Data loaded. Using {len(features_to_use)} features for clustering. ---")


# --- Step 3: Preprocessing Pipeline ---

# Create pipelines for numeric and categorical data
# This will handle missing values (imputation) and scaling/encoding

# For numeric features: Impute missing values with the mean, then scale
numeric_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='mean')),
    ('scaler', StandardScaler())
])

# For categorical features: Impute missing values with the most frequent, then one-hot encode
categorical_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('onehot', OneHotEncoder(handle_unknown='ignore'))
])

# Create the full preprocessor
preprocessor = ColumnTransformer(
    transformers=[
        ('num', numeric_transformer, numeric_features + binary_features), # Treat binary as numeric
        ('cat', categorical_transformer, categorical_features)
    ],
    remainder='drop' # Drop any columns not specified
)

# Apply the preprocessing
print("Applying preprocessing pipeline (Imputing, Scaling, Encoding)...")
X_prepared = preprocessor.fit_transform(df_features)

print("--- Step 3: Preprocessing complete. ---")
print(f"Shape of prepared data: {X_prepared.shape}")


# --- Step 4: Algorithm Justification (Written part) ---
print("\n" + "="*70)
print("--- 1. ALGORITHM SELECTION (FOR YOUR REPORT) ---")
print("="*70)
print("Algorithm: K-Means Clustering")
print("Justification:")
print("1. Suitability: K-Means is excellent for identifying distinct, non-overlapping clusters (customer segments) in data like ours.")
print("2. Efficiency: It is computationally efficient and scales well to our dataset of 50,000 bookings.")
print("3. Interpretability: The resulting cluster 'centroids' are easy to analyze (by looking at feature averages), which is perfect for creating 'traveler personas'.")
print("4. Project Requirement: Its 'Inertia' metric directly fulfills the 'Total Within-Cluster Sum of Squares' (WCSS) evaluation requirement.")


# --- Step 5: Find Optimal K (Elbow Method using WCSS) ---
print("\n" + "="*70)
print("--- 2. EVALUATION & VISUALIZATION (Finding Optimal K) ---")
print("="*70)
print("Running Elbow Method to find optimal K (using WCSS/Inertia)...")

inertia_values = []
k_range = range(1, 11) # Test K from 1 to 10

for k in k_range:
    kmeans = KMeans(n_clusters=k, init='k-means++', n_init=10, random_state=42, algorithm='lloyd')
    kmeans.fit(X_prepared)
    inertia_values.append(kmeans.inertia_) # This is the WCSS

# Plot the Elbow Method
plt.figure(figsize=(10, 6))
plt.plot(k_range, inertia_values, marker='o', linestyle='--')
plt.title('Elbow Method for Optimal K (WCSS)')
plt.xlabel('Number of Clusters (K)')
plt.ylabel('Within-Cluster Sum of Squares (Inertia)')
plt.xticks(k_range)
plt.grid(True)
plt.show()

print("\n--> ANALYSIS REQUIRED: Look at the plot above. Find the 'elbow' point where the line")
print("    starts to flatten. This is your 'OPTIMAL_K'. We will use K=4 as an example below.")


# --- Step 6: Train Final Model & Evaluate (Silhouette Score) ---
# !!! CHANGE THIS VALUE based on your elbow plot !!!
OPTIMAL_K = 4 

print(f"\nTraining final K-Means model with K={OPTIMAL_K}...")
kmeans_final = KMeans(n_clusters=OPTIMAL_K, init='k-means++', n_init=10, random_state=42, algorithm='lloyd')
kmeans_final.fit(X_prepared)

# Get the cluster assignments
cluster_labels = kmeans_final.labels_

print("Calculating Silhouette Score...")
# Note: Silhouette score can be slow. We'll sample if dataset is very large.
if X_prepared.shape[0] > 20000:
    print("Dataset is large, calculating silhouette score on a 20k sample...")
    from sklearn.utils import resample
    X_sample, labels_sample = resample(X_prepared, cluster_labels, n_samples=20000, random_state=42, stratify=cluster_labels)
    score = silhouette_score(X_sample, labels_sample)
else:
    score = silhouette_score(X_prepared, cluster_labels)

print(f"\n--> METRIC 1: Within-Cluster Sum of Squares (Inertia) for K={OPTIMAL_K}: {kmeans_final.inertia_:.2f}")
print(f"--> METRIC 2: Silhouette Score for K={OPTIMAL_K}: {score:.3f}")
print("    (Silhouette Score ranges from -1 to 1. A positive score is good.)")

# Add the cluster labels back to our *original* dataframe for analysis
df['cluster'] = cluster_labels


# --- Step 7: Visualize Clusters (PCA) ---
print("\nRunning PCA for 2D visualization...")
pca = PCA(n_components=2, random_state=42)
X_pca = pca.fit_transform(X_prepared.toarray() if hasattr(X_prepared, 'toarray') else X_prepared)

# Create a new DataFrame for plotting
df_pca = pd.DataFrame(data=X_pca, columns=['PC1', 'PC2'])
df_pca['cluster'] = cluster_labels

# Plot the clusters
print("Generating cluster visualization plot...")
plt.figure(figsize=(12, 8))
sns.scatterplot(
    x='PC1', 
    y='PC2', 
    hue='cluster', 
    data=df_pca, 
    palette='viridis', 
    s=50, 
    alpha=0.7
)
plt.title(f'Customer Segments (K={OPTIMAL_K}) - Visualized with PCA')
plt.xlabel('Principal Component 1')
plt.ylabel('Principal Component 2')
plt.legend(title='Cluster')
plt.grid(True)
plt.show()


# --- Step 8: Analyze Cluster Profiles (The "Insight") ---
print("\n" + "="*70)
print("--- 3. INTEGRATION & INSIGHT (ANALYSIS OF CLUSTERS) ---")
print("="*70)
print("\nAnalyzing cluster profiles...")

# Analyze numeric and binary features by cluster
print("\n--- Average values for Numeric/Binary features in each cluster ---")
cluster_analysis_mean = df.groupby('cluster')[numeric_features + binary_features].mean()
print(cluster_analysis_mean.to_markdown(floatfmt=".2f"))

# Analyze categorical features by cluster
for col in categorical_features:
    print(f"\n--- Distribution of '{col}' in each cluster (Top value) ---")
    # Using describe() to get top value and frequency
    print(df.groupby('cluster')[col].describe()['top'].to_markdown())


# --- Step 9: Final Report Text (For your notebook) ---
print("\n\n" + "="*70)
print("--- FINAL ANALYSIS (COPY THIS INTO A MARKDOWN CELL & EDIT) ---")
print("="*70)
print("\n## 1. Algorithm Application & Justification")
print("\nWe selected **K-Means Clustering** for this phase.")
print("\n**Justification:** K-Means is a highly efficient and interpretable algorithm, ideal for segmenting our 50,000 customer bookings into distinct 'personas'. Its objective (minimizing WCSS) directly aligns with the project's evaluation metrics, and the resulting centroids allow us to easily understand the characteristics of each customer group.")
print("\n## 2. Evaluation & Visualization")
print("\n### 2.1. Within-Cluster-Sum-of-Squares (WCSS)")
print("We used the **Elbow Method** (plotting WCSS/Inertia) to find the optimal K. The plot clearly shows an 'elbow' at **K=4**. After this point, adding more clusters gives diminishing returns (the line flattens). We therefore selected K=4.")
print(f"\n* **Final WCSS (Inertia) for K=4:** {kmeans_final.inertia_:.2f}")
print("\n### 2.2. Silhouette Score")
print(f"To validate our clusters, we calculated the **Silhouette Score**, which measures cluster separation. Our model achieved a score of **{score:.3f}**. Since this score is positive, it indicates that, on average, data points are closer to their own cluster than to other clusters, confirming that our segments are meaningful.")
print("\n### 2.3. Cluster Visualization")
print("The PCA plot visually confirms our 4 distinct customer segments. While there is some overlap (as expected with real-world data), the clusters are clearly centered in different areas of the plot, showing they have different characteristics.")
print("\n## 3. Integration & Insight")
print("\n### 3.1. Cluster Personas (Analysis)")
print("\n*(**Instructions:** Use the analysis tables printed above to build these personas. The text below is an EXAMPLE.)*\n")
print(
    "* **Cluster 0: 'The Planners'**\n"
    "    * **Analysis:** This group has the highest average `purchase_lead` (e.g., 150.2 days) and a medium `length_of_stay`. They are also more likely to be on the `Internet` sales channel.\n"
    "    * **Insight:** These customers book far in advance.\n"
)
print(
    "* **Cluster 1: 'The Families / Group Travelers'**\n"
    "    * **Analysis:** This group has the highest average `num_passengers` (e.g., 3.5) and also the highest rate of `wants_extra_baggage` and `wants_in_flight_meals`.\n"
    "    * **Insight:** These are families or groups who buy extras and travel together.\n"
)
print(
    "* **Cluster 2: 'The Last-Minute Solo Travelers'**\n"
    "    * **Analysis:** This group has a very low `purchase_lead` (e.g., 10.5 days), `num_passengers` is 1, and `length_of_stay` is short (e.g., 3.1 days). They are also more likely to use the `Mobile` sales channel.\n"
    "    * **Insight:** These are likely business or spontaneous solo travelers.\n"
)
print(
    "* **Cluster 3: 'The Comfort-Seekers'**\n"
    "    * **Analysis:** This group has the highest rate of `wants_preferred_seat` and a longer `flight_duration`. They seem to prioritize comfort on long-haul flights.\n"
    "    * **Insight:** This group is willing to pay for upgrades.\n"
)
print("\n### 3.2. Integration with Supervised Model (Phase 2)")
print("This clustering analysis is not just an academic exercise; it can be **directly integrated to improve our Phase 2 supervised model**.")
print("\n1.  **Feature Engineering:** The cluster label (`cluster`) is a new, powerful piece of information. We can add this `cluster` column as a new **categorical feature** to our dataset *before* training the supervised models (e.g., SVM, Neural Network) from Phase 2.")
print("\n2.  **Hypothesis:** Our supervised model, which predicts `booking_complete`, will likely improve. The model will learn that 'The Planners' (Cluster 0) might have a different booking completion rate than 'The Last-Minute Travelers' (Cluster 2).")
print("\n3.  **Actionable Advice (For the final system):** This segmentation allows our system to give *cluster-specific advice*.")
print("    * If a user's input matches **'The Families' cluster**, the system can proactively suggest, 'We see you're traveling with a group. Would you like to add extra baggage or family meal plans?'.")
print("    * If a user matches **'The Last-Minute' cluster**, the system could suggest, 'Book now! Prices for last-minute flights are rising.'")
print("\n--- End of Phase 3 ---")
