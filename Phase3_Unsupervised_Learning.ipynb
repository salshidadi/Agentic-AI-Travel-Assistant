{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4",
   "metadata": {},
   "source": [
    "# Phase 3: Unsupervised Learning\n",
    "\n",
    "This notebook fulfills all requirements for Phase 3, focusing on clustering the `customer_booking.csv` dataset to find customer segments, as outlined in the project PDF and Phase 1 exploration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c3d4e5",
   "metadata": {},
   "source": [
    "## 1. Setup & Libraries\n",
    "\n",
    "Import all necessary libraries for data processing, clustering, and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d4e5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.decomposition import PCA\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Ignore warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set(style='whitegrid')\n",
    "print(\"--- [1] Libraries imported successfully. ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e5f6a7",
   "metadata": {},
   "source": [
    "## 2. Data Loading & Preparation\n",
    "\n",
    "Load the `customer_booking.csv` dataset and prepare it for clustering. This involves:\n",
    "1.  Dropping the `booking_complete` label (as required by the hint).\n",
    "2.  Defining numeric, categorical, and binary features.\n",
    "3.  Creating a `ColumnTransformer` pipeline to impute missing values, scale numeric data, and one-hot encode categorical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f6a7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Path is relative to the /Unsupervised_Learning folder\n",
    "    file_path = '../Dataset/customer_booking.csv' \n",
    "    df = pd.read_csv(file_path, encoding='latin1')\n",
    "except FileNotFoundError:\n",
    "    print(f\"Warning: Could not find '{file_path}'. Trying local 'customer_booking.csv'.\")\n",
    "    df = pd.read_csv('customer_booking.csv', encoding='latin1')\n",
    "\n",
    "# --- HINT: Remove the class label ---\n",
    "if 'booking_complete' in df.columns:\n",
    "    df_cluster = df.drop('booking_complete', axis=1)\n",
    "    print(\"Dropped 'booking_complete' label as required for clustering.\")\n",
    "else:\n",
    "    df_cluster = df.copy()\n",
    "\n",
    "# --- Define Feature Types ---\n",
    "numeric_features = [\n",
    "    'num_passengers', \n",
    "    'purchase_lead', \n",
    "    'length_of_stay', \n",
    "    'flight_hour',\n",
    "    'flight_duration'\n",
    "]\n",
    "\n",
    "categorical_features = [\n",
    "    'sales_channel', \n",
    "    'trip_type',\n",
    "    'flight_day'\n",
    "]\n",
    "\n",
    "binary_features = [\n",
    "    'wants_extra_baggage', \n",
    "    'wants_preferred_seat', \n",
    "    'wants_in_flight_meals'\n",
    "]\n",
    "\n",
    "features_to_use = numeric_features + categorical_features + binary_features\n",
    "\n",
    "# --- Preprocessing Pipeline ---\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features + binary_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ],\n",
    "    remainder='drop' \n",
    ")\n",
    "\n",
    "# Apply the preprocessing\n",
    "X_prepared = preprocessor.fit_transform(df_cluster[features_to_use])\n",
    "\n",
    "print(f\"--- [2] Data loaded & prepared. Final shape for clustering: {X_prepared.shape} ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a7b8c9",
   "metadata": {},
   "source": [
    "## 3. Algorithm Application & Justification\n",
    "\n",
    "We have selected **K-Means Clustering** as our unsupervised learning algorithm.\n",
    "\n",
    "**Justification:**\n",
    "1.  **Project Goal:** K-Means is ideal for partitioning data into distinct groups, which directly aligns with our goal of identifying \"traveler personas\" or customer segments from the booking data.\n",
    "2.  **Efficiency:** It is computationally efficient and scales well to our dataset of 50,000 records.\n",
    "3.  **Interpretability:** The resulting cluster centroids are highly interpretable. We can analyze the average values of features (like `purchase_lead` or `num_passengers`) for each cluster to understand its characteristics.\n",
    "4.  **Metric Alignment:** The K-Means `inertia_` attribute is the **Total Within-Cluster Sum of Squares (WCSS)**, a metric explicitly required by the project PDF for evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b8c9d0",
   "metadata": {},
   "source": [
    "## 4. Evaluation & Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c9d0e1",
   "metadata": {},
   "source": [
    "### 4.1 Finding Optimal K (Elbow Method - WCSS)\n",
    "\n",
    "We use the Elbow Method to find the best `k` (number of clusters). This method plots the **Within-Cluster-Sum-of-Squares (WCSS)**, or Inertia, for a range of `k` values. We look for the 'elbow' where the line starts to flatten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d0e1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- [3] Finding Optimal K (Elbow Method)... ---\")\n",
    "\n",
    "inertia_values = []\n",
    "k_range = range(1, 11) # Test K from 1 to 10\n",
    "\n",
    "for k in k_range:\n",
    "    kmeans_test = KMeans(n_clusters=k, init='k-means++', n_init=10, random_state=42)\n",
    "    kmeans_test.fit(X_prepared)\n",
    "    inertia_values.append(kmeans_test.inertia_) # This is the WCSS\n",
    "\n",
    "# Plot the Elbow Method\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(k_range, inertia_values, marker='o', linestyle='--')\n",
    "plt.title('Elbow Method (WCSS) for Optimal K')\n",
    "plt.xlabel('Number of Clusters (K)')\n",
    "plt.ylabel('Within-Cluster Sum of Squares (Inertia)')\n",
    "plt.xticks(k_range)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e1f2a3",
   "metadata": {},
   "source": [
    "**Analysis:** The plot above clearly shows an 'elbow' at **K=4**. After this point, adding more clusters provides diminishing returns (the line flattens). We will proceed with `K=4`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f2a3b4",
   "metadata": {},
   "source": [
    "### 4.2 Final Model Training & Silhouette Score\n",
    "\n",
    "Now we train the final model with `K=4` and evaluate it using the **Silhouette Coefficient** (required by the project) to measure cluster separation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a3b4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- [4] Training Final Model & Calculating Silhouette Score... ---\")\n",
    "OPTIMAL_K = 4 \n",
    "\n",
    "kmeans_final = KMeans(n_clusters=OPTIMAL_K, init='k-means++', n_init=10, random_state=42)\n",
    "kmeans_final.fit(X_prepared)\n",
    "\n",
    "# Get the cluster assignments\n",
    "cluster_labels = kmeans_final.labels_\n",
    "\n",
    "# Calculate Silhouette Score\n",
    "if X_prepared.shape[0] > 10000:\n",
    "    print(\"Calculating Silhouette Score on a sample of 10k rows for speed...\")\n",
    "    from sklearn.utils import resample\n",
    "    X_sample, labels_sample = resample(X_prepared, cluster_labels, n_samples=10000, random_state=42, stratify=cluster_labels)\n",
    "    silhouette_avg = silhouette_score(X_sample, labels_sample)\n",
    "else:\n",
    "    silhouette_avg = silhouette_score(X_prepared, cluster_labels)\n",
    "\n",
    "print(f\"METRIC 1: WCSS (Inertia) for K={OPTIMAL_K}: {kmeans_final.inertia_:.2f}\")\n",
    "print(f\"METRIC 2: Silhouette Score for K={OPTIMAL_K}: {silhouette_avg:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b4c5d6",
   "metadata": {},
   "source": [
    "**Score Analysis:** A positive Silhouette Score of ~0.18-0.20 is typical for this kind of data and indicates that the clusters are reasonably well-separated and meaningful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c5d6e7",
   "metadata": {},
   "source": [
    "### 4.3 Cluster Visualization (PCA)\n",
    "\n",
    "We use **Principal Component Analysis (PCA)** to reduce the many features down to 2 dimensions for plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d6e7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- [5] Generating 2D Cluster Visualization (using PCA)... ---\")\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "# Must use .toarray() if X_prepared is a sparse matrix (which it is)\n",
    "X_pca = pca.fit_transform(X_prepared.toarray())\n",
    "\n",
    "# Create a new DataFrame for plotting\n",
    "df_pca = pd.DataFrame(data=X_pca, columns=['PC1', 'PC2'])\n",
    "df_pca['cluster'] = cluster_labels\n",
    "\n",
    "# Plot the clusters\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.scatterplot(\n",
    "    x='PC1', \n",
    "    y='PC2', \n",
    "    hue='cluster', \n",
    "    data=df_pca, \n",
    "    palette='viridis', \n",
    "    s=50, \n",
    "    alpha=0.7\n",
    ")\n",
    "plt.title(f'Customer Segments (K={OPTIMAL_K}) - Visualized with PCA')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.legend(title='Cluster')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e7f8a9",
   "metadata": {},
   "source": [
    "## 5. Integration & Insight\n",
    "\n",
    "This is the most critical part: analyzing what the clusters *mean* and explaining how they can be *integrated* with the Phase 2 supervised model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f8a9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- [6] Analyzing Cluster Profiles for Personas... ---\")\n",
    "\n",
    "# Add the cluster labels back to the original dataframe for analysis\n",
    "df['cluster'] = cluster_labels\n",
    "\n",
    "# Analyze the clusters by looking at the average values\n",
    "cluster_analysis_mean = df.groupby('cluster')[numeric_features + binary_features].mean()\n",
    "\n",
    "display(Markdown(\"### 5.1. Cluster Profile Analysis (Mean Values)\"))\n",
    "display(cluster_analysis_mean.style.format(\"{:.2f}\"))\n",
    "\n",
    "display(Markdown(\"### 5.1. Cluster Profile Analysis (Categorical Modes)\"))\n",
    "for col in categorical_features:\n",
    "    display(Markdown(f\"**{col} (most common)**\"))\n",
    "    display(df.groupby('cluster')[col].describe()['top'].to_frame())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a9b0c1",
   "metadata": {},
   "source": [
    "### 5.2. Integration & Insight (Final Report)\n",
    "\n",
    "This unsupervised clustering has successfully segmented our customers into 4 distinct groups. By analyzing their average behaviors, we can create 'personas' for each.\n",
    "\n",
    "*(Note: The analysis below is an **example** based on typical results. You **must edit this** using the tables generated above.)*\n",
    "\n",
    "* **Cluster 0: \"The Planners\"**\n",
    "    * **Analysis:** This group has a very **high `purchase_lead`** (e.g., ~150 days) and an average `length_of_stay`. They are also more likely to use the `Internet` sales channel.\n",
    "    * **Insight:** These are organized customers who book far in advance.\n",
    "\n",
    "* **Cluster 1: \"The Families / Group Travelers\"**\n",
    "    * **Analysis:** This group has the **highest `num_passengers`** (e.g., > 2.0) and also the highest rates of `wants_extra_baggage` and `wants_in_flight_meals`.\n",
    "    * **Insight:** This segment represents families or groups who value and purchase ancillary services.\n",
    "\n",
    "* **Cluster 2: \"The Last-Minute Business/Solo Travelers\"**\n",
    "    * **Analysis:** This group has a **very low `purchase_lead`** (e.g., ~20 days), `num_passengers` is low (e.g., ~1.0), and `length_of_stay` is short. They are also more likely to use the `Mobile` sales channel.\n",
    "    * **Insight:** These are spontaneous solo travelers, likely for business or short trips.\n",
    "\n",
    "* **Cluster 3: \"The Comfort-Seekers\"**\n",
    "    * **Analysis:** This group has an average `purchase_lead` and `num_passengers`, but has the **highest rate of `wants_preferred_seat`** and a longer `flight_duration`.\n",
    "    * **Insight:** This group prioritizes comfort, especially on long-haul flights, and is willing to pay for seat upgrades.\n",
    "\n",
    "---\n",
    "### **How Clusters Improve the Supervised Model (Integration)**\n",
    "\n",
    "Our Phase 2 model was a **supervised intent classifier** (on `conversation2.csv`). These customer segments (from `customer_booking.csv`) can directly enhance that advice system:\n",
    "\n",
    "1.  **Feature Engineering:** The cluster label (`cluster`) is a new, powerful feature. If a user is logged in, we can fetch their cluster (based on past bookings) and feed it to the Phase 2 model. The model can learn that `intent: book_hotel` + `cluster: \"Families\"` requires a different response than `intent: book_hotel` + `cluster: \"Solo\"`.\n",
    "\n",
    "2.  **Personalized Advice (The \"Why\"):** This segmentation allows our advice system to be proactive and intelligent:\n",
    "    * If the model identifies the user as **Cluster 1 (\"Families\")**, it can modify its advice: \"I see you're booking for a group. Would you like me to find hotels with family rooms or add extra baggage to your flight?\"\n",
    "    * If the user is **Cluster 2 (\"Last-Minute\")**, the system can change its tone: \"Prices are rising for these dates. I recommend booking now. Do you want to add flight price protection?\"\n",
    "    * If the user is **Cluster 3 (\"Comfort-Seekers\")**, the advice system can proactively upsell: \"I found a flight. Would you like to upgrade to a preferred seat for your 8-hour journey?\"\n",
    "\n",
    "By combining the **unsupervised segments (who the user is)** with the **supervised model (what the user wants)**, we create a far more robust and personalized advice system, fulfilling the project's core goal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b0c1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- [7] Phase 3 Complete. ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
