{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "\n",
    "# Install pyarrow if you haven't already, it's needed to read .parquet files\n",
    "# You can run this cell once by removing the '#' from the line below\n",
    "#!pip install pyarrow\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 1: Problem Understanding and Data Exploration\n",
    "\n",
    "This notebook serves as the first deliverable for the SWE485 project. The goal of this phase is to define the project's objective, select and explore the datasets that will be used, and outline a plan for data preprocessing.\n",
    "\n",
    "## 1. The Dataset Goal & Source\n",
    "\n",
    "Our project requires a multifaceted understanding of the travel booking domain, from customer behavior to conversational patterns and real-world flight logistics. No single dataset can provide all this information. Therefore, we are adopting a **composite dataset strategy**, using multiple specialized datasets to build a comprehensive foundation for our AI model.\n",
    "\n",
    "### Our Datasets:\n",
    "\n",
    "1.  **Customer Booking Behavior Dataset**\n",
    "    * **Goal:** To understand the patterns and preferences of travelers. This dataset contains 50,000 anonymized booking records, providing crucial insights into how far in advance people book, trip duration, and preferences for ancillary services. This data will be vital for our unsupervised learning model in Phase 3 to identify traveler personas.\n",
    "    * **Source:** [https://www.kaggle.com/datasets/ememque/customer-booking](https://www.kaggle.com/datasets/ememque/customer-booking)\n",
    "\n",
    "2.  **Synthetic Airline Passenger and Flight Dataset**\n",
    "    * **Goal:** To augment our understanding of user behavior with more detailed passenger demographics and flight information. This synthetic dataset includes features like passenger age, income level, and travel purpose, which are essential for building a more personalized recommendation engine.\n",
    "    * **Source:** [https://www.kaggle.com/datasets/keatonballard/synthetic-airline-passenger-and-flight-data](https://www.kaggle.com/datasets/keatonballard/synthetic-airline-passenger-and-flight-data)\n",
    "\n",
    "3.  **King Khalid International Airport (Riyadh) Flights Dataset**\n",
    "    * **Goal:** To ground our project in a realistic, local context relevant to the Saudi market. This dataset contains real flight information for arrivals and departures from Riyadh's airport. We will use it to extract authentic flight routes, destinations, and airline carriers.\n",
    "    * **Source:** [https://www.kaggle.com/datasets/mohammedalsubaie/king-khalid-international-airport-flights-dataset/data](https://www.kaggle.com/datasets/mohammedalsubaie/king-khalid-international-airport-flights-dataset/data)\n",
    "    \n",
    "4.  **Hotel Booking Conversational Datasets**\n",
    "    * **Goal:** To understand the structure and flow of a typical booking conversation. These datasets contain dialogues between a user and a booking assistant. We will analyze these conversations to identify common user intents (e.g., `book_hotel`), required information (entities like `destination`, `dates`), and the assistant's questions. This will be the blueprint for our synthetic Arabic dataset in Phase 2.\n",
    "    * **Sources:**\n",
    "        * [https://huggingface.co/datasets/M-A-E/hotel-booking-assistant-raw-chats](https://huggingface.co/datasets/M-A-E/hotel-booking-assistant-raw-chats)\n",
    "        * [https://huggingface.co/datasets/KvrParaskevi/hotel_data](https://huggingface.co/datasets/KvrParaskevi/hotel_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths to the datasets in the /Dataset folder\n",
    "booking_behavior_path = 'Dataset/customer_booking.csv'\n",
    "synthetic_passenger_path = 'Dataset/synthetic_flight_passenger_data.csv'\n",
    "riyadh_flights_path = 'Dataset/flights_RUH.parquet'  # CORRECTED FILENAME AND EXTENSION\n",
    "hotel_chats_path = 'Dataset/conversations.parquet' # CORRECTED FILENAME AND EXTENSION\n",
    "hotel_data_path = 'Dataset/conversation2.csv'\n",
    "\n",
    "# Load the datasets into pandas DataFrames\n",
    "try:\n",
    "    df_booking = pd.read_csv(booking_behavior_path, encoding='latin1') # Added encoding for compatibility\n",
    "    df_passenger = pd.read_csv(synthetic_passenger_path)\n",
    "    df_riyadh = pd.read_parquet(riyadh_flights_path)      # CORRECTED READ FUNCTION\n",
    "    df_chats = pd.read_parquet(hotel_chats_path)          # CORRECTED READ FUNCTION\n",
    "    df_hotel_data = pd.read_csv(hotel_data_path)\n",
    "    print(\"All datasets loaded successfully!\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error loading datasets: {e}\")\n",
    "    print(\"Please ensure all data files are in the '/Dataset' folder with the correct names.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    print(\"You may need to install 'pyarrow' or 'fastparquet' to read parquet files. Try: pip install pyarrow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. General Information\n",
    "\n",
    "In this section, we will inspect each dataset to understand its structure, data types, and key features.\n",
    "\n",
    "### 2.1 Customer Booking Behavior Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Customer Booking Behavior Dataset ---\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "display(df_booking.head())\n",
    "print(\"\\nDataset Info:\")\n",
    "df_booking.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Features Description:**\n",
    "* `num_passengers`: The number of passengers in the booking.\n",
    "* `sales_channel`: The channel used for booking (Internet or Mobile).\n",
    "* `purchase_lead`: Number of days between the booking date and the travel date.\n",
    "* `length_of_stay`: The duration of the stay at the destination in days.\n",
    "* `flight_day`: The day of the week for the flight departure.\n",
    "* `route`: The flight route (origin and destination airport codes).\n",
    "* `wants_extra_baggage`, `wants_preferred_seat`, `wants_in_flight_meals`: Boolean flags for ancillary service preferences.\n",
    "* `booking_complete`: Our potential target variable, indicating if the booking was completed (1) or not (0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Synthetic Airline Passenger and Flight Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Synthetic Airline Passenger and Flight Dataset ---\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "display(df_passenger.head())\n",
    "print(\"\\nDataset Info:\")\n",
    "df_passenger.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Features Description:**\n",
    "* `Airline`, `Departure_Airport`, `Arrival_Airport`: Basic flight details.\n",
    "* `Price_USD`: The price of the ticket.\n",
    "* `Age`, `Gender`, `Income_Level`: Passenger demographic information.\n",
    "* `Travel_Purpose`: The reason for travel (e.g., Business, Leisure, Family).\n",
    "* `Seat_Class`: The class of the seat booked.\n",
    "* `Booking_Days_In_Advance`: Similar to `purchase_lead`, useful for understanding booking behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 King Khalid International Airport (Riyadh) Flights Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- King Khalid International Airport (Riyadh) Flights Dataset ---\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "display(df_riyadh.head())\n",
    "print(\"\\nDataset Info:\")\n",
    "df_riyadh.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Features Description:**\n",
    "* `flight_date`: The date of the flight.\n",
    "* `direction`: Whether the flight is an 'Arrival' or 'Departure'.\n",
    "* `time_scheduled`, `time_actual`: Scheduled and actual times, useful for analyzing delays.\n",
    "* `flight_number`: The unique flight identifier.\n",
    "* `airline`: The name of the airline.\n",
    "* `origin`, `destination`: The airport codes for the flight route. This is the most valuable feature for our project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Hotel Booking Conversational Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Hotel Booking Assistant Chats Dataset (conversations.parquet) ---\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "display(df_chats.head())\n",
    "\n",
    "print(\"\\n--- Hotel Data (conversation2.csv) ---\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "display(df_hotel_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Features Description:**\n",
    "* These datasets are text-based and capture dialogues between a \"user\" or \"human\" and an \"assistant\" or \"agent\".\n",
    "* The content reveals the questions a user asks (their **intent**) and the information they provide (the **entities**), such as destination, dates, and number of guests.\n",
    "* Analyzing these conversations is crucial for designing the logic of our own conversational agent and for creating the training data for our NLU model in Phase 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Summary & Visualization (Exploratory Data Analysis)\n",
    "\n",
    "Here, we will perform EDA to uncover initial insights from the tabular datasets.\n",
    "\n",
    "### 3.1 Statistical Summary of Booking Behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Statistical Summary of the Customer Booking Behavior Dataset:\")\n",
    "display(df_booking.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initial Observations:**\n",
    "* The average `purchase_lead` is about 85 days, but the standard deviation is high (90 days), and the max is 867 days. This indicates a wide range of booking behaviors.\n",
    "* The average `length_of_stay` is around 23 days, which seems quite long and might be skewed by outliers.\n",
    "* Most bookings are for 1-2 passengers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Missing Value Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Missing values in Customer Booking Behavior dataset:\")\n",
    "print(df_booking.isnull().sum())\n",
    "print(\"\\nMissing values in Synthetic Passenger dataset:\")\n",
    "print(df_passenger.isnull().sum())\n",
    "print(\"\\nMissing values in Riyadh Flights dataset:\")\n",
    "print(df_riyadh.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Missing Value Findings:**\n",
    "* The `customer_booking` and `synthetic_flight_passenger` datasets are clean with no missing values, which is excellent for modeling.\n",
    "* The `riyadh_airport_flights` dataset has missing values in `time_actual` and `status`, which is logical as these fields are only populated after a flight has departed or landed. For our purposes of extracting routes, this is not an issue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Visualizations\n",
    "\n",
    "#### Visualization 1: How Do Customers Book? (Sales Channel Distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(data=df_booking, x='sales_channel')\n",
    "plt.title('Distribution of Sales Channels', fontsize=16)\n",
    "plt.xlabel('Sales Channel', fontsize=12)\n",
    "plt.ylabel('Number of Bookings', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insight:** The vast majority of bookings are made via the **Internet** compared to Mobile. This suggests that while a mobile presence is important, the primary user interaction happens on the web platform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization 2: How Far in Advance Do People Book?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 7))\n",
    "sns.histplot(df_booking['purchase_lead'], bins=50, kde=True)\n",
    "plt.title('Distribution of Purchase Lead Time (in days)', fontsize=16)\n",
    "plt.xlabel('Days Between Booking and Travel', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "plt.xlim(0, 400) # Limiting to 400 days to see the main distribution\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insight:** The distribution is heavily skewed to the right. A very large number of customers book their flights shortly before the travel date (less than 50 days in advance), while a smaller number plan their trips many months ahead. Our AI agent should be able to handle both last-minute and long-term planning requests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization 3: What is the Purpose of Travel?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "# Use value_counts().index to ensure the order is from most frequent to least\n",
    "order = df_passenger['Travel_Purpose'].value_counts().index\n",
    "sns.countplot(data=df_passenger, x='Travel_Purpose', order=order)\n",
    "plt.title('Distribution of Travel Purpose', fontsize=16)\n",
    "plt.xlabel('Travel Purpose', fontsize=12)\n",
    "plt.ylabel('Number of Passengers', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insight:** The travel purposes are evenly distributed across Business, Emergency, Family, and Leisure in this synthetic dataset. This is a good reminder that our agent must be able to cater to different user needs and priorities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization 4: Top 10 Busiest Routes from Riyadh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are interested in all routes, both arrivals and departures\n",
    "# First, drop rows where 'destination' is null or empty, as they can't be analyzed\n",
    "df_riyadh_cleaned = df_riyadh.dropna(subset=['destination'])\n",
    "top_10_destinations = df_riyadh_cleaned['destination'].value_counts().nlargest(10)\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.barplot(x=top_10_destinations.index, y=top_10_destinations.values, palette='viridis')\n",
    "plt.title('Top 10 Busiest Destinations from/to Riyadh (RUH)', fontsize=16)\n",
    "plt.xlabel('Destination Airport Code', fontsize=12)\n",
    "plt.ylabel('Number of Flights', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insight:** This chart shows the most frequent destinations connected to Riyadh. Jeddah (JED), Dammam (DMM), and Dubai (DXB) are clearly major hubs. This real-world data is invaluable for generating realistic training examples for our agent (e.g., \"Book a flight from Riyadh to Jeddah\").\n",
    "\n",
    "## 4. Preprocessing Techniques\n",
    "\n",
    "Based on the initial exploration, we have formulated the following plan for data preprocessing, which will be implemented in the subsequent phases of the project.\n",
    "\n",
    "1.  **Handling Categorical Data (Phase 2):**\n",
    "    * The `flight_day` column in `df_booking` is textual ('Mon', 'Tue', etc.). We will convert this into numerical format (e.g., 1 for Monday, 2 for Tuesday) so it can be used by machine learning models.\n",
    "    * Other categorical columns like `sales_channel`, `Travel_Purpose`, and `Seat_Class` will be one-hot encoded to convert them into a numerical format suitable for modeling.\n",
    "\n",
    "2.  **Feature Engineering (Phase 3):**\n",
    "    * We can create a new feature, such as `is_weekend`, from the `flight_day` column to see if weekend travel has a different pattern.\n",
    "    * From the `route` column, we can extract `origin` and `destination` as separate features to analyze travel patterns more granularly.\n",
    "\n",
    "3.  **Text Data Processing (Phase 2):**\n",
    "    * The conversational datasets (`df_chats`, `df_hotel_data`) will be parsed to create a structured dataset for training our Natural Language Understanding (NLU) model.\n",
    "    * Each user utterance will be labeled with an **intent** (e.g., `request_hotel`, `provide_dates`).\n",
    "    * Key pieces of information within the text will be identified and labeled as **entities** (e.g., \"Paris\" -> `destination`, \"tomorrow\" -> `date`).\n",
    "\n",
    "4.  **Synthetic Dataset Generation (Phase 2):**\n",
    "    * The core of our data strategy will be to create a large, custom Arabic conversational dataset.\n",
    "    * We will use the dialogue flows from the English conversational datasets as templates.\n",
    "    * We will populate these templates with realistic entities extracted from the tabular datasets, especially the routes and airlines from the Riyadh airport dataset, to ensure local relevance. This synthetic dataset will be the primary training data for our supervised learning model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
