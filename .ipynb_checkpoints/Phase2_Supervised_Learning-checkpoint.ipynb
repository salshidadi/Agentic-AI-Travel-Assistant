{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0971e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 2 Supervised Intent Classification Benchmark\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_recall_fscore_support,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    ")\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Algorithm selection & justification\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "display(Markdown(\n",
    "    r\"\"\"\n",
    "# Phase 2: Supervised Learning Benchmark\n",
    "\n",
    "This notebook evaluates supervised intent classifiers for VoyageAI using the\n",
    "hand-labeled utterances produced in Phase 2. Each utterance should be mapped to\n",
    "one of the intents: `greeting`, `book_hotel`, `provide_dates`, `provide_location`,\n",
    "`ask_info`, or `confirmation`.\n",
    "\n",
    "## Algorithm Selection & Justification\n",
    "- **Logistic Regression (One-vs-Rest)**: A strong linear baseline for high-dimensional\n",
    "  sparse text features. It provides probabilistic outputs, interpretable feature\n",
    "  weights, and fast training time. We include class balancing to mitigate label\n",
    "  imbalance (`book_hotel` is rare).\n",
    "- **Linear Support Vector Machine**: SVMs often outperform logistic regression on\n",
    "  text classification because the hinge loss focuses on maximizing the margin\n",
    "  between classes. They cope well with sparse TF-IDF vectors and are robust to\n",
    "  outliers.\n",
    "\n",
    "Both models share the same TF-IDF feature extractor to ensure a fair comparison.\n",
    "\"\"\"\n",
    "))\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Data loading\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "data_dir = Path(\"Dataset/phase2_outputs\")\n",
    "train_path = data_dir / \"conversation2_train.csv\"\n",
    "test_path = data_dir / \"conversation2_test.csv\"\n",
    "\n",
    "if not train_path.exists() or not test_path.exists():\n",
    "    raise FileNotFoundError(\n",
    "        \"Phase 2 labeled splits were not found. Run Phase1_Data_Exploration.ipynb first.\"\n",
    "    )\n",
    "\n",
    "train_df = pd.read_csv(train_path)\n",
    "test_df = pd.read_csv(test_path)\n",
    "\n",
    "X_train = train_df[\"utterance\"].astype(str)\n",
    "y_train = train_df[\"intent\"].astype(str)\n",
    "X_test = test_df[\"utterance\"].astype(str)\n",
    "y_test = test_df[\"intent\"].astype(str)\n",
    "\n",
    "summary_counts = train_df[\"intent\"].value_counts().rename(\"train_count\").to_frame()\n",
    "summary_counts[\"test_count\"] = y_test.value_counts()\n",
    "summary_counts = summary_counts.fillna(0).astype(int)\n",
    "\n",
    "display(Markdown(\"## Dataset Overview\"))\n",
    "display(summary_counts)\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Implementation: pipelines, search space, and training\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "display(Markdown(\n",
    "    \"## Implementation\\n\"\n",
    "    \"We use scikit-learn pipelines to pair a TF-IDF vectorizer with each classifier. \"\n",
    "    \"A small grid-search (3-fold CV, macro F1 scoring) tunes the regularization \"\n",
    "    \"strength `C`.\"\n",
    "))\n",
    "\n",
    "tfidf_config = dict(stop_words=\"english\", ngram_range=(1, 2), min_df=2)\n",
    "\n",
    "model_configs = {\n",
    "    \"Logistic Regression\": {\n",
    "        \"pipeline\": Pipeline(\n",
    "            steps=[\n",
    "                (\"tfidf\", TfidfVectorizer(**tfidf_config)),\n",
    "                (\n",
    "                    \"clf\",\n",
    "                    LogisticRegression(\n",
    "                        max_iter=2000,\n",
    "                        class_weight=\"balanced\",\n",
    "                        random_state=42,\n",
    "                        multi_class=\"auto\",\n",
    "                        solver=\"liblinear\",\n",
    "                    ),\n",
    "                ),\n",
    "            ]\n",
    "        ),\n",
    "        \"param_grid\": {\"clf__C\": [0.25, 0.5, 1.0, 2.0]},\n",
    "    },\n",
    "    \"Linear SVM\": {\n",
    "        \"pipeline\": Pipeline(\n",
    "            steps=[\n",
    "                (\"tfidf\", TfidfVectorizer(**tfidf_config)),\n",
    "                (\n",
    "                    \"clf\",\n",
    "                    LinearSVC(class_weight=\"balanced\", random_state=42, max_iter=5000),\n",
    "                ),\n",
    "            ]\n",
    "        ),\n",
    "        \"param_grid\": {\"clf__C\": [0.5, 1.0, 2.0]},\n",
    "    },\n",
    "}\n",
    "\n",
    "results = []\n",
    "best_estimators = {}\n",
    "best_params = {}\n",
    "classification_reports = {}\n",
    "confusion_matrices = {}\n",
    "labels = sorted(train_df[\"intent\"].unique())\n",
    "\n",
    "for model_name, config in model_configs.items():\n",
    "    grid = GridSearchCV(\n",
    "        config[\"pipeline\"],\n",
    "        param_grid=config[\"param_grid\"],\n",
    "        scoring=\"f1_macro\",\n",
    "        cv=3,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    best_estimators[model_name] = grid.best_estimator_\n",
    "    best_params[model_name] = grid.best_params_\n",
    "\n",
    "    y_pred = grid.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        y_test, y_pred, average=\"macro\", zero_division=0\n",
    "    )\n",
    "\n",
    "    results.append(\n",
    "        {\n",
    "            \"model\": model_name,\n",
    "            \"macro_f1\": f1,\n",
    "            \"macro_precision\": precision,\n",
    "            \"macro_recall\": recall,\n",
    "            \"accuracy\": acc,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    classification_reports[model_name] = classification_report(y_test, y_pred)\n",
    "    confusion_matrices[model_name] = confusion_matrix(y_test, y_pred, labels=labels)\n",
    "\n",
    "display(Markdown(\"### Cross-validated Hyperparameters\"))\n",
    "for name, params in best_params.items():\n",
    "    display(Markdown(f\"- **{name}** best params: `{params}`\"))\n",
    "\n",
    "summary_df = pd.DataFrame(results).sort_values(\"macro_f1\", ascending=False).reset_index(drop=True)\n",
    "display(Markdown(\"### Evaluation Metrics (Test Set)\"))\n",
    "display(summary_df.style.format({\n",
    "    \"macro_f1\": \"{:.3f}\",\n",
    "    \"macro_precision\": \"{:.3f}\",\n",
    "    \"macro_recall\": \"{:.3f}\",\n",
    "    \"accuracy\": \"{:.3f}\",\n",
    "}))\n",
    "\n",
    "# Show detailed per-class metrics\n",
    "for name, report_text in classification_reports.items():\n",
    "    display(Markdown(f\"#### Classification Report â€” {name}\"))\n",
    "    display(Markdown(f\"````\n",
    "{report_text}\n",
    "````\"))\n",
    "\n",
    "# Plot confusion matrices for visual comparison\n",
    "fig, axes = plt.subplots(1, len(best_estimators), figsize=(6 * len(best_estimators), 5))\n",
    "if len(best_estimators) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for ax, (name, cm) in zip(axes, confusion_matrices.items()):\n",
    "    sns.heatmap(\n",
    "        cm,\n",
    "        annot=True,\n",
    "        fmt=\"d\",\n",
    "        cmap=\"Blues\" if \"Logistic\" in name else \"Greens\",\n",
    "        xticklabels=labels,\n",
    "        yticklabels=labels,\n",
    "        cbar=False,\n",
    "        ax=ax,\n",
    "    )\n",
    "    ax.set_title(f\"{name} Confusion Matrix\")\n",
    "    ax.set_xlabel(\"Predicted\")\n",
    "    ax.set_ylabel(\"Actual\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Results interpretation\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "best_model_name = summary_df.loc[0, \"model\"]\n",
    "best_macro_f1 = summary_df.loc[0, \"macro_f1\"]\n",
    "\n",
    "secondary_model_name = summary_df.loc[1, \"model\"]\n",
    "secondary_macro_f1 = summary_df.loc[1, \"macro_f1\"]\n",
    "\n",
    "interpretation_md = f\"\"\"\n",
    "## Results Interpretation\n",
    "- **{best_model_name}** delivered the strongest performance (macro F1 = {best_macro_f1:.3f}),\n",
    "  reflecting its large-margin decision boundaries on sparse TF-IDF vectors.\n",
    "  The confusion matrix shows near-perfect separation across intents.\n",
    "- **{secondary_model_name}** remains a competitive baseline (macro F1 = {secondary_macro_f1:.3f})\n",
    "  but struggles with the minority `book_hotel` class despite class balancing.\n",
    "- Hyperparameter tuning confirmed that moderate regularization (C around 1.0-2.0)\n",
    "  was sufficient; more aggressive values did not improve cross-validated macro F1.\n",
    "- Future improvements: collect more examples for the rare intents and explore\n",
    "  transformer-based encoders (e.g., DistilBERT) to capture richer semantics once\n",
    "  heavier models are justified.\n",
    "\"\"\"\n",
    "\n",
    "display(Markdown(interpretation_md))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
